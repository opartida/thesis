{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B decay model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate cos_theta\n",
    "from sympy import * \n",
    "a_l, x = symbols('a_l x')\n",
    "integrate(a_l - a_l * x**2, (x,-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sympy import * \n",
    "from sympy.solvers import solve\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import math \n",
    "import sys\n",
    "import scipy.integrate as integrate\n",
    "import decimal\n",
    "from matplotlib import pyplot as plt\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def lambda_(q):\n",
    "    return M_B**4 + M_K**4 + q**4 - 2 * (M_B**2 * M_K**2 + M_B**2 * q**2 + M_K**2 * q**2)\n",
    "\n",
    "def f(q, K, M, Gamma, Gamma_channel):\n",
    "    C = coeff(Gamma_channel)\n",
    "    return (K * C) / ((np.square(q) - M**2)**2 + Gamma**2 * M**2)\n",
    "\n",
    "def integrand(u, M, Gamma):\n",
    "    return  (1 / ((u - M**2)**2 + Gamma**2 * M**2))\n",
    "\n",
    "def sm_integrand(q, cos_theta):\n",
    "    return  a_l(q) - a_l(q) * cos_theta**2\n",
    "\n",
    "def sm(q, cos_theta):    \n",
    "    return  a_l(q) - a_l(q) * cos_theta**2\n",
    "\n",
    "def coeff(Gamma_channel):\n",
    "    return (9 * math.pi * Gamma_channel) / (alpha_e**2)\n",
    "\n",
    "def a_l(q):\n",
    "    l = lambda_(q)\n",
    "    frho = f(q, K_rho, M_rho, Gamma_rho, Gamma_rho_e)\n",
    "    fphi = f(q, K_phi, M_phi, Gamma_phi, Gamma_phi_e)\n",
    "    fpsi = f(q, K_psi, M_psi, Gamma_psi, Gamma_psi_e)\n",
    "    F = frho + fphi + fpsi\n",
    "    F = np.array(F, dtype='float64')\n",
    "    return (F**2 * 8 * l**(3/2) * G_F**2 * alpha_e**2 * abs(V_tb * V_ts)**2) / (512 * math.pi**5 * M_B**3)   \n",
    "\n",
    "def K(M, Gamma, Gamma_channel):\n",
    "    K = symbols('K')\n",
    "    C = coeff(Gamma_channel)\n",
    "    I = integrate.quad(integrand, -np.inf, np.inf, args=(M, Gamma))\n",
    "    return solve(K * C * I[0] - 1, K)[0]\n",
    "\n",
    "def Ksm():\n",
    "    K = symbols('K')\n",
    "    I = integrate.dblquad(sm_integrand, 0, np.inf,-1,1)\n",
    "    return solve(K *  I[0] - 1, K)[0]\n",
    "\n",
    "def metropolis_hastings(p, iter=10000000):\n",
    "    x, y = 0., 0.\n",
    "    samples = np.zeros((iter - 10**3, 2))\n",
    "    scale = 0.2\n",
    "        \n",
    "    for i in range(iter):\n",
    "        x_star, y_star = np.array([x, y]) + scale * np.random.normal(size=2)\n",
    "        if y_star <= 1 and y_star >= -1 and x_star >= 0:  \n",
    "            if (not math.isnan(p(x_star, y_star)) and \n",
    "                math.log(np.random.rand()) < p(x_star, y_star) - p(x, y) \n",
    "                and p(x_star, y_star) - p(x, y) > 0):\n",
    "                x, y = x_star, y_star\n",
    "                \n",
    "            if i > 10**3:\n",
    "                samples[i] = np.array([x, y])\n",
    "\n",
    "    return samples\n",
    "\n",
    "# constants\n",
    "alpha_e = 1/137\n",
    "\n",
    "# rho meson\n",
    "M_rho = 0.77\n",
    "Gamma_rho = 0.150\n",
    "Gamma_rho_e = 7 * 10**(-6)\n",
    "\n",
    "# phi meson\n",
    "M_phi = 1.020\n",
    "Gamma_phi = 4.26 * 10**(-3)\n",
    "Gamma_phi_e = 1.25 * 10**(-6)\n",
    "\n",
    "#psi meson\n",
    "M_psi = 3.096\n",
    "Gamma_psi = 92.9 * 10**(-6)\n",
    "Gamma_psi_e = 5.55 * 10**(-6)\n",
    "\n",
    "G_F = 1.1663 * 10**(-5)\n",
    "M_B = 5366.79 * 10**(-3) # Strange B meson\n",
    "M_K = 497.648 * 10**(-3) # Neutral kaon ds_bar\n",
    "\n",
    "V_tb = 1.019\n",
    "V_ts = 39.4 * 10**(-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from pylab import meshgrid,cm,imshow,contour,clabel,colorbar,axis,title,show\n",
    "\n",
    "K_rho = K(M_rho, Gamma_rho, Gamma_rho_e)\n",
    "K_phi = K(M_phi, Gamma_phi, Gamma_phi_e)\n",
    "K_psi = K(M_psi, Gamma_psi, Gamma_psi_e)\n",
    "\n",
    "K_sm = Ksm();\n",
    "\n",
    "samples = metropolis_hastings(sm, iter=1000)\n",
    "sns.jointplot(samples[:, 0], samples[:, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data();\n",
    "\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('b_meson.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('b_meson.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.argmax(predictions[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0], cmap = plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying Cats vs Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "DATADIR = 'datasets/PetImages/'\n",
    "CATEGORIES = ['Dog', 'Cat']\n",
    "\n",
    "IMG_SIZE = 70\n",
    "\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in training_data[:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out = open(\"X.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "tensorBoard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "\n",
    "#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "#gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.333) \n",
    "#sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "pickle_in = open(\"X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\", \"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "dense_layers = [0, 1, 2]\n",
    "layer_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2 ,3]\n",
    "\n",
    "dense_layers = [0]\n",
    "layer_sizes = [64]\n",
    "conv_layers = [3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3,3), input_shape = X.shape[1:]))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))            \n",
    "            \n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3,3)))\n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            model.add(Flatten())\n",
    "                \n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(Dropout(0.2))\n",
    "\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            model.compile(loss=\"binary_crossentropy\",\n",
    "                         optimizer=\"adam\",\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "            model.fit(X, y, batch_size=32, epochs=10, validation_split=0.3, callbacks=[tensorBoard])\n",
    "\n",
    "model.save('64x3-CNN.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CATEGORIES = [\"Dog\", \"Cat\"]\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 50\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE,IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "model = tf.keras.models.load_model('64x3-CNN.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict([prepare('dog.jpg')])\n",
    "print(CATEGORIES[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CuDNNLSTM' from 'tensorflow.keras.layers' (C:\\Users\\Oliver\\anaconda3\\lib\\site-packages\\tensorflow\\keras\\layers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-c5c0215882fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCuDNNLSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'CuDNNLSTM' from 'tensorflow.keras.layers' (C:\\Users\\Oliver\\anaconda3\\lib\\site-packages\\tensorflow\\keras\\layers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, CuDNNLSTM\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(128, input_shape=(x_train.shape[1:]), activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-3, decay=1e-5)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer=opt,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1, validation_data=(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B decay model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Integrate cos_theta\n",
    "from sympy import * \n",
    "a_l, x = symbols('a_l x')\n",
    "integrate(a_l - a_l * x**2, (x,-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sympy import * \n",
    "from sympy.solvers import solve\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import math \n",
    "import sys\n",
    "import scipy.integrate as integrate\n",
    "import decimal\n",
    "from matplotlib import pyplot as plt\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def lambda_(q):\n",
    "    return M_B**4 + M_K**4 + q**4 - 2 * (M_B**2 * M_K**2 + M_B**2 * q**2 + M_K**2 * q**2)\n",
    "\n",
    "def f(q, K, M, Gamma, Gamma_channel):\n",
    "    C = coeff(Gamma_channel)\n",
    "    return (K * C) / ((np.square(q) - M**2)**2 + Gamma**2 * M**2)\n",
    "\n",
    "def integrand(u, M, Gamma):\n",
    "    return  (1 / ((u - M**2)**2 + Gamma**2 * M**2))\n",
    "\n",
    "def sm_integrand(q, cos_theta):\n",
    "    return  a_l(q) - a_l(q) * cos_theta**2\n",
    "\n",
    "def sm(q, cos_theta):    \n",
    "    return  a_l(q) - a_l(q) * cos_theta**2\n",
    "\n",
    "def coeff(Gamma_channel):\n",
    "    return (9 * math.pi * Gamma_channel) / (alpha_e**2)\n",
    "\n",
    "def a_l(q):\n",
    "    l = lambda_(q)\n",
    "    frho = f(q, K_rho, M_rho, Gamma_rho, Gamma_rho_e)\n",
    "    fphi = f(q, K_phi, M_phi, Gamma_phi, Gamma_phi_e)\n",
    "    fpsi = f(q, K_psi, M_psi, Gamma_psi, Gamma_psi_e)\n",
    "    F = frho + fphi + fpsi\n",
    "    F = np.array(F, dtype='float64')\n",
    "    return (F**2 * 8 * l**(3/2) * G_F**2 * alpha_e**2 * abs(V_tb * V_ts)**2) / (512 * math.pi**5 * M_B**3)   \n",
    "\n",
    "def K(M, Gamma, Gamma_channel):\n",
    "    K = symbols('K')\n",
    "    C = coeff(Gamma_channel)\n",
    "    I = integrate.quad(integrand, -np.inf, np.inf, args=(M, Gamma))\n",
    "    return solve(K * C * I[0] - 1, K)[0]\n",
    "\n",
    "def Ksm():\n",
    "    K = symbols('K')\n",
    "    I = integrate.dblquad(sm_integrand, 0, np.inf,-1,1)\n",
    "    return solve(K *  I[0] - 1, K)[0]\n",
    "\n",
    "def metropolis_hastings(p, iter=10000000):\n",
    "    x, y = 0., 0.\n",
    "    samples = np.zeros((iter - 10**3, 2))\n",
    "    scale = 0.2\n",
    "        \n",
    "    for i in range(iter):\n",
    "        x_star, y_star = np.array([x, y]) + scale * np.random.normal(size=2)\n",
    "        if y_star <= 1 and y_star >= -1 and x_star >= 0:  \n",
    "            if (not math.isnan(p(x_star, y_star)) and \n",
    "                math.log(np.random.rand()) < p(x_star, y_star) - p(x, y) \n",
    "                and p(x_star, y_star) - p(x, y) > 0):\n",
    "                x, y = x_star, y_star\n",
    "                \n",
    "            if i > 10**3:\n",
    "                samples[i] = np.array([x, y])\n",
    "\n",
    "    return samples\n",
    "\n",
    "# constants\n",
    "alpha_e = 1/137\n",
    "\n",
    "# rho meson\n",
    "M_rho = 0.77\n",
    "Gamma_rho = 0.150\n",
    "Gamma_rho_e = 7 * 10**(-6)\n",
    "\n",
    "# phi meson\n",
    "M_phi = 1.020\n",
    "Gamma_phi = 4.26 * 10**(-3)\n",
    "Gamma_phi_e = 1.25 * 10**(-6)\n",
    "\n",
    "#psi meson\n",
    "M_psi = 3.096\n",
    "Gamma_psi = 92.9 * 10**(-6)\n",
    "Gamma_psi_e = 5.55 * 10**(-6)\n",
    "\n",
    "G_F = 1.1663 * 10**(-5)\n",
    "M_B = 5366.79 * 10**(-3) # Strange B meson\n",
    "M_K = 497.648 * 10**(-3) # Neutral kaon ds_bar\n",
    "\n",
    "V_tb = 1.019\n",
    "V_ts = 39.4 * 10**(-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from pylab import meshgrid,cm,imshow,contour,clabel,colorbar,axis,title,show\n",
    "\n",
    "K_rho = K(M_rho, Gamma_rho, Gamma_rho_e)\n",
    "K_phi = K(M_phi, Gamma_phi, Gamma_phi_e)\n",
    "K_psi = K(M_psi, Gamma_psi, Gamma_psi_e)\n",
    "\n",
    "K_sm = Ksm();\n",
    "\n",
    "samples = metropolis_hastings(sm, iter=1000)\n",
    "sns.jointplot(samples[:, 0], samples[:, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computation of overlap with KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def computeKL(mu1, mu2, sigma1, sigma2, ax):    \n",
    "    v1 = np.random.normal(mu1, sigma1, 100000)\n",
    "    v2 = np.random.normal(mu2, sigma2, 100000)\n",
    "\n",
    "    count, bins, ignored = ax.hist(v1, 30, density=True, color='green')\n",
    "    count2, bins2, ignored = ax.hist(v2, 30, density=True, color='orange')   \n",
    "    \n",
    "    minValue = min(min(bins),min(bins2))\n",
    "    maxValue = max(max(bins),max(bins2))\n",
    "    x = np.linspace(minValue, maxValue, 1000)\n",
    "    y1 = 1/(sigma1 * np.sqrt(2 * np.pi)) * np.exp( - (x - mu1)**2 / (2 * sigma1**2) )\n",
    "    y2 = 1/(sigma2 * np.sqrt(2 * np.pi)) * np.exp( - (x - mu2)**2 / (2 * sigma2**2) )\n",
    "    ax.plot(x, y1, linewidth=2, color='r')\n",
    "    ax.plot(x, y2 , linewidth=2, color='b')\n",
    "    \n",
    "    return entropy(y1, y2)\n",
    "    \n",
    "def computeOverlap(df1, df2):\n",
    "    result = [[mu1,mu2,sigma1,sigma2] for mu1,mu2,sigma1,sigma2 in zip(df1['BinValue'],df2['BinValue'], df1['ErrorPlus'],df2['ErrorPlus'])]\n",
    "    fig = plt.figure()\n",
    "    fig.set_figheight(25)\n",
    "    fig.set_figwidth(15)\n",
    "    index = 1\n",
    "    kls = []\n",
    "    \n",
    "    for mu1,mu2,sigma1,sigma2 in result:\n",
    "        ax = fig.add_subplot(len(result), 2, index)        \n",
    "        index = index + 1\n",
    "        kl = computeKL(mu1, mu2, sigma1, sigma2, ax)\n",
    "        ax.set_title('Kullback-Liebler divergence: {}'.format(kl))\n",
    "        kls.append(kl)\n",
    "    plt.show()\n",
    "    return np.mean(kls)   \n",
    "    \n",
    "\n",
    "def experiment1():\n",
    "    EXPDIR = 'data\\experimental'\n",
    "    DATADIR = 'data\\models\\observables'\n",
    "    MODELSDIR = 'data\\models'\n",
    "    filename = 'models.txt'\n",
    "    \n",
    "    models = pd.read_csv(os.path.join(MODELSDIR, filename))  \n",
    "    \n",
    "    for i in models.index:\n",
    "        model = models.iloc[[i]]\n",
    "        \n",
    "        modelName = model['Name'][i]\n",
    "        C9 = model['C9'][i]\n",
    "        C10 = model['C10'][i]\n",
    "        fig = plt.figure()\n",
    "        fig.set_figheight(15)\n",
    "        fig.set_figwidth(15)\n",
    "        fig.subplots_adjust(wspace=0.5)\n",
    "        index = 1\n",
    "        #for filename in os.listdir(DATADIR):\n",
    "        filename = 'P4.txt'\n",
    "        fname = filename.split('.')[0]            \n",
    "        title = '{}, {}'.format(fname, 'Experimental')\n",
    "        \n",
    "        ax = fig.add_subplot(8,2,index)\n",
    "        ax.set_title(title)\n",
    "        df1 = getExperimentalObservable(EXPDIR, filename)\n",
    "        \n",
    "        plotExperimentalObservable(df1, ax, 'green', 'black') \n",
    "        index = index + 1   \n",
    "\n",
    "        ax = fig.add_subplot(8,2,index)   \n",
    "        title = '{}, {}'.format(modelName, fname)\n",
    "        ax.set_title(title)\n",
    "        df2 = getModelObservable(DATADIR, filename, C9, C10)\n",
    "\n",
    "        plotModelObservable(df2, ax, 'orange', 'black')\n",
    "        index = index + 1         \n",
    "\n",
    "        overlap = computeOverlap(df1, df2)\n",
    "        \n",
    "        print('Total Overlap: {}'.format(overlap))\n",
    "    \n",
    "    \n",
    "experiment1()\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the Pandas libraries with alias 'pd' \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.colors as Colors\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.stats import entropy\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import math\n",
    "from scipy.stats import chisquare\n",
    "from scipy import stats\n",
    "from itertools import product\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "def plotAllModelsObservables(models, coeffs):\n",
    "    \n",
    "    \n",
    "    observables = loadObservables()\n",
    "    \n",
    "    numObservables = len(observables)\n",
    "    nrows = math.ceil(numObservables/2)\n",
    "    ncols = 2\n",
    "    nrows =3\n",
    "    ncols =3\n",
    "    imageWidth = 6\n",
    "    imageHeight = 5\n",
    "    hspace = 0.5\n",
    "    wspace = 0.5\n",
    "    figureHeight = nrows * imageHeight + (nrows - 1) * hspace\n",
    "    figureWidth = ncols * imageWidth + (ncols - 1) * wspace\n",
    "    \n",
    "    plt.rc('text', usetex=True)\n",
    "    plt.rcParams['text.latex.preamble']=[r\"\\usepackage{amsmath}\"]    \n",
    "    \n",
    "    \n",
    "    for C9, C10 in models:    \n",
    "        index = 1\n",
    "        fig, axs = plt.subplots(nrows,ncols)\n",
    "        fig.subplots_adjust(left=None, right=None, bottom=None, top=0.90, hspace=hspace, wspace=wspace)  \n",
    "        fig.set_figheight(figureHeight)\n",
    "        fig.set_figwidth(figureWidth)\n",
    "        fig.delaxes(axs[2,2])\n",
    "        axs = np.reshape(axs,(-1))\n",
    "        axis_index = 0\n",
    "        allFits=[]\n",
    "        for mo, eo in observables:\n",
    "            \n",
    "            #fig.suptitle(title, fontsize=18) \n",
    "            df = mo['data']\n",
    "            de = eo['data']\n",
    "            \n",
    "            ax = axs[axis_index]            \n",
    "            \n",
    "            observableName = mo['name']\n",
    "            \n",
    "            ax.set_xlabel(r'\\(\\boldsymbol{q^2(GeV^2)}\\)', fontsize=16)\n",
    "            print(observableName)\n",
    "            if(observableName == 'RKStar'):\n",
    "                ytitle = 'R'\n",
    "                ax.set_ylabel(r'\\(\\langle \\boldsymbol{{{}_K^*}} \\rangle\\)'.format(ytitle), fontsize=16)\n",
    "            elif(observableName=='BRK0mumu'):\n",
    "                ytitle = 'B'\n",
    "                ax.set_ylabel(r'\\(\\langle \\boldsymbol{{\\mathcal{B}(B^0\\rightarrow K\\mu\\mu)}} \\rangle\\)', fontsize=16)\n",
    "            elif(observableName=='BRK0Starmumu'):\n",
    "                ytitle = 'B'\n",
    "                ax.set_ylabel(r'\\(\\langle \\boldsymbol{{\\mathcal{B}(B^0\\rightarrow K^{*0}\\mu\\mu)}} \\rangle\\)', fontsize=16)\n",
    "            elif(observableName == 'P5'):\n",
    "                ytitle = 'P'\n",
    "                ax.set_ylabel(r'\\(\\langle \\boldsymbol{{{}_5}} \\rangle\\)'.format(ytitle), fontsize=16)\n",
    "            else:\n",
    "                ax.set_ylabel(r'\\(\\langle \\boldsymbol{{{}}} \\rangle\\)'.format(observableName), fontsize=16)\n",
    "                \n",
    "            computeModelObservable(df, C9, C10)\n",
    "            if(len(coeffs) > 0):\n",
    "                addQPoly(df,coeffs[axis_index])\n",
    "                \n",
    "            fit = computeModelFit(df, de)\n",
    "            print(fit)\n",
    "            print(coeffs[axis_index])\n",
    "            allFits.append(fit)\n",
    "            ax.set_title(r'\\(\\chi^2:{} \\)'.format(round(fit,2)), fontsize=20)\n",
    "            ax.set_xlim(0, max(df['BinHigh'].max(), de['BinHigh'].max()))\n",
    "            ax.set_ylim([min(df['MinValue'].min(),de['MinValue'].min()), max(df['MaxValue'].max(),de['MaxValue'].max())])\n",
    "            \n",
    "            plotObservable(ax, df, 'orange', 'black', 1)\n",
    "            plotObservable(ax, de, 'black', 'green', 0, True, True)\n",
    "            index = index + 1 \n",
    "            \n",
    "            axis_index = axis_index + 1\n",
    "        title = r'Model: C9: {}, C10: {}, \\(\\chi^2: {} \\)'.format(C9, C10,round(np.array(allFits).sum(),2))         \n",
    "        fig.suptitle(title, fontsize=24) \n",
    "        fig.savefig('observableImages/{}.svg'.format('AllObservables'))\n",
    "    plt.show()\n",
    "   \n",
    "    \n",
    "    \n",
    "def expandObservableData(df):\n",
    "    df['Widths'] = df['BinHigh'] - df['BinLow']\n",
    "    df['Heights'] = df['ErrorPlus'] + df['ErrorMinus']  \n",
    "    \n",
    "       \n",
    "\n",
    "def plotObservable(ax, df, color,kcolor, opacity, yerrorbar = False, onlyErrorBars = False):   \n",
    "    patches = [Rectangle((x,y), w, h) for x,y,w,h in zip(df['BinLow'], df['MinValue'], df['Widths'], df['Heights'])]\n",
    "    xerror = [df['Widths'] / 2, df['Widths'] / 2]    \n",
    "    \n",
    "    if(not onlyErrorBars):\n",
    "        p = PatchCollection(patches, facecolor=Colors.to_rgba(color, opacity))\n",
    "        ax.add_collection(p)       \n",
    "    ax.errorbar(df['BinLow'] + df['Widths']/2, df['BinValue'], xerr=xerror, fmt='None', ecolor=Colors.to_rgba(kcolor, 1))\n",
    "    if(yerrorbar):\n",
    "        yerror = [df['Heights'] / 2, df['Heights'] / 2] \n",
    "        ax.errorbar(df['BinLow'] + df['Widths']/2, df['BinValue'], yerr=yerror, fmt='None', ecolor=Colors.to_rgba(kcolor, 1))\n",
    "\n",
    "\n",
    "def computePoly(binCoeffs,c9,c10):\n",
    "    a = binCoeffs[0]\n",
    "    b = binCoeffs[1]*c10\n",
    "    c = binCoeffs[2]*c10**2\n",
    "    d = binCoeffs[3]*c9\n",
    "    e = binCoeffs[4]*c10*c9\n",
    "    f = binCoeffs[5]*c9**2\n",
    "    return a + b + c  + d + e + f\n",
    "\n",
    "def getBinValuesFreeCoeffs(df, c9, c10, observableCoeffs):     \n",
    "    df['BinValue'] = [computePoly(binCoeffs,c9,c10) for binCoeffs in observableCoeffs]\n",
    "    \n",
    "        \n",
    "def getBinValues(df, C9, C10):     \n",
    "    df2 = df.copy();       \n",
    "    df2['C10'] = df2['C10']*C10\n",
    "    df2['C10^2'] = df2['C10^2']*C10**2\n",
    "    df2['C9'] = df2['C9']*C9\n",
    "    df2['C10*C9']=df2['C10*C9']*C10*C9\n",
    "    df2['C9^2'] = df2['C9^2']*C9**2    \n",
    "    df['BinValue'] = df['C0'] + df2['C10'] + df2['C10^2'] + df2['C9'] + df2['C10*C9'] + df2['C9^2']\n",
    "    df['MinValue'] = df['BinValue'] - df['ErrorMinus']\n",
    "    df['MaxValue'] = df['BinValue'] + df['ErrorPlus']\n",
    "\n",
    "def getModelObservable(DATADIR, filename) :\n",
    "    return getObservable(DATADIR, filename)\n",
    "\n",
    "def getExpObservable(DATADIR, filename) :\n",
    "    eo = getObservable(DATADIR, filename)\n",
    "    df = eo['data']\n",
    "    df['MinValue'] = df['BinValue'] - df['ErrorMinus']\n",
    "    df['MaxValue'] = df['BinValue'] + df['ErrorPlus']\n",
    "    return eo\n",
    "\n",
    "def getObservable(DATADIR, filename):\n",
    "    try:  \n",
    "        df = pd.read_csv(os.path.join(DATADIR, filename))\n",
    "        expandObservableData(df)\n",
    "        fname = filename.split('.')[0]  \n",
    "        if(fname=='P1'):   \n",
    "            print('')\n",
    "            #df=df.drop([1])\n",
    "        elif(fname=='P2'):\n",
    "            print('')\n",
    "            #df=df.drop([0])\n",
    "        elif(fname=='P5'):\n",
    "            print('')\n",
    "            #df=df.drop([3,4,5])        \n",
    "        return {'name': fname, 'data': df}\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    \n",
    "def computeModelFit(dfm, dfe):\n",
    "    data = zip(dfm['BinValue'], dfe['BinValue'], (dfm['ErrorPlus']+dfm['ErrorMinus'])/2, (dfe['ErrorPlus']+dfe['ErrorMinus'])/2)\n",
    "    binFits = [computeChiSquare(muModel, muExp, sigmaModel, sigmaExp) for muModel, muExp, sigmaModel, sigmaExp in data]      \n",
    "    s = sum(binFits)\n",
    "    return s\n",
    "        \n",
    "def computeChiSquare(muModel, muExp, sigmaModel, sigmaExp):   \n",
    "    return (muExp - muModel)**2/(sigmaModel**2 + sigmaExp**2)\n",
    "    \n",
    "\n",
    "def getObservables(DATADIR, EXPDIR, names):\n",
    "    observables = []\n",
    "    for filename in names:\n",
    "        mo = getModelObservable(DATADIR, filename)        \n",
    "        eo = getExpObservable(EXPDIR, filename)\n",
    "        observables.append([mo, eo])\n",
    "    return observables\n",
    "    \n",
    "def getAllObservables():\n",
    "    DATADIR = 'data/models/observables' \n",
    "    EXPDIR = 'data/experimental'     \n",
    "    onlyfiles = [f for f in listdir(DATADIR) if isfile(join(DATADIR, f))]    \n",
    "    return getObservables(DATADIR, EXPDIR, onlyfiles)   \n",
    "\n",
    "def computeRandomModelsFit(observables):    \n",
    "    models = getRandomModels()\n",
    "    return computeModelsFit(models, observables)    \n",
    "\n",
    "def getCoeffsFromModels(models):\n",
    "    m = [[c9, c10] for c9, c10 in zip(models['C9'], models['C10'])]\n",
    "    return m\n",
    "    \n",
    "def getModels():\n",
    "    MODELSDIR = 'data/models'  \n",
    "    mfilename = 'models1.txt'    \n",
    "    models = pd.read_csv(os.path.join(MODELSDIR, mfilename))\n",
    "    return models\n",
    "\n",
    "def addQPoly(dfe, coeffs):\n",
    "    dfe['q^2'] = (dfe['BinHigh'] + dfe['BinLow']) / 2\n",
    "    \n",
    "    dfe['Fq^2Net'] = coeffs[0]  + coeffs[1] * dfe['q^2'] + coeffs[2] * dfe['q^2']**2\n",
    "    \n",
    "    dfe['BinValueOld'] = dfe['BinValue']\n",
    "    dfe['BinValue'] = dfe['BinValue'] + dfe['Fq^2Net']  \n",
    "    dfe['BinValueDiff'] = dfe['BinValue'] - dfe['BinValueOld']\n",
    "    dfe['MinValue'] = dfe['BinValue'] - dfe['ErrorMinus']\n",
    "    dfe['MaxValue'] = dfe['BinValue'] + dfe['ErrorPlus']\n",
    "    \n",
    "        \n",
    "def computeModelObservable(df, C9, C10):\n",
    "    getBinValues(df,C9, C10) \n",
    "    expandObservableData(df)\n",
    "\n",
    "def getObservablesByName(DATADIR, EXPDIR, names):\n",
    "    names = [f for f in listdir(DATADIR) if isfile(join(DATADIR, f)) and f.split('.')[0] in names]\n",
    "    return getObservables(DATADIR, EXPDIR, names)     \n",
    "\n",
    "    \n",
    "def computeAllModelsAllFit():\n",
    "    DATADIR = 'data/models/observables' \n",
    "    EXPDIR = 'data/experimental'  \n",
    "    models = getModels()\n",
    "    m = getCoeffsFromModels(models)\n",
    "    observables = getAllObservables()\n",
    "    #observables = getObservablesByName(DATADIR, EXPDIR, ['P5'])\n",
    "    return computeModelsFit(m, observables)\n",
    "\n",
    "def getValue(value, low, high ):    \n",
    "    #print('value: {}, high: {}, low: {}, newValue: {}'.format(value,high,low, random.uniform(value - low, value + high)))\n",
    "    return np.random.normal(value, low)\n",
    "\n",
    "def generateExperimental():    \n",
    "    observables = loadObservables()\n",
    "    x = np.array([])\n",
    "    for mo, eo in observables:\n",
    "        dfe = eo['data']\n",
    "        x = np.append(x, dfe['BinValue'].values)\n",
    "        \n",
    "    saveData(\"X_experimental.pickle\", x)\n",
    "    return x\n",
    "\n",
    "def saveData(filename, data):\n",
    "    pickle_out = open(filename, \"wb\")\n",
    "    pickle.dump(data, pickle_out)\n",
    "    pickle_out.close()         \n",
    "\n",
    "    \n",
    "def generateBinErrors():\n",
    "    observables = loadObservables() \n",
    "    \n",
    "    errors = np.empty([0,6]);\n",
    "    for mo, eo in observables:\n",
    "        \n",
    "        dfm = mo['data']\n",
    "        dfe = eo['data']\n",
    "        expandObservableData(dfm)\n",
    "        expandObservableData(dfe)\n",
    "        dfmErrorMinus = dfm['ErrorMinus']  \n",
    "        dfeErrorMinus = dfe['ErrorMinus']  \n",
    "        dfmError = dfm['Heights'].values\n",
    "        dfeError = dfe['Heights'].values\n",
    "        widths = dfe['Widths'].values\n",
    "        bins = dfm['BinLow'].values\n",
    "        errors = np.append(errors, [[a,b,c,d,e,f] for a,b,c,d,e,f in zip(dfmError,dfeError,widths,bins,dfmErrorMinus,dfeErrorMinus)],axis=0)\n",
    "     \n",
    "    saveData(\"errors.pickle\", errors)\n",
    "    \n",
    "\n",
    "def generateObservableNumBins():\n",
    "    observables = loadObservables() \n",
    "    \n",
    "    numBins = []\n",
    "    for mo, eo in observables:\n",
    "        dfe = eo['data']\n",
    "        numBins.append(len(dfe.index))\n",
    "     \n",
    "    saveData(\"numBins.pickle\", numBins)\n",
    "    print(numBins)\n",
    "\n",
    "\n",
    "    \n",
    "def genNNWithCoeffsData():\n",
    "    observables = loadObservables()  \n",
    "    models = getRandomModels()\n",
    "   \n",
    "    X = []\n",
    "    Y = []\n",
    "    coeffs = []\n",
    "    numPolyCoeffs = 100\n",
    "    iter=0   \n",
    "    bestFit=100000\n",
    "    bestq=[]\n",
    "    bestc=[]\n",
    "    for c9, c10 in models:\n",
    "        print(iter)\n",
    "        iter=iter+1        \n",
    "        \n",
    "        for i in range(numPolyCoeffs):  \n",
    "            \n",
    "            allFits = []      \n",
    "            x = []\n",
    "            y = np.array([])\n",
    "            allQSquareCoeffs = np.array([])            \n",
    "            fits=[]\n",
    "            numObs = 0\n",
    "            \n",
    "            for mo, eo in observables:\n",
    "                dfm = mo['data']\n",
    "                dfe = eo['data']                \n",
    "                \n",
    "                computeModelObservable(dfm,c9, c10)\n",
    "                \n",
    "                if(i==0):\n",
    "                    QSsquareCoeffs = np.random.uniform(0, 0, 3)                \n",
    "                else:\n",
    "                    QSsquareCoeffs = [rnd() for _ in range(3)]\n",
    "                    QSsquareCoeffs[1] = QSsquareCoeffs[1]/10\n",
    "                    QSsquareCoeffs[2] = QSsquareCoeffs[2]/100\n",
    "                    QSsquareCoeffs = np.round(QSsquareCoeffs,2)\n",
    "                  \n",
    "                \n",
    "                allQSquareCoeffs = np.append(allQSquareCoeffs, QSsquareCoeffs)                \n",
    "                addQPoly(dfm, QSsquareCoeffs)                \n",
    "                fit = computeModelFit(dfm, dfe)\n",
    "                fits.append(fit)\n",
    "                \n",
    "                #x = x + np.round(dfm['BinValue'].values,2).tolist()\n",
    "                x = x + dfm['BinValue'].values.tolist()\n",
    "                numObs = numObs + 1\n",
    "                \n",
    "            \n",
    "            y = np.append(y,[c9,c10])     \n",
    "            y = np.append(y, allQSquareCoeffs)\n",
    "            fit = np.array(fits).sum()\n",
    "            if(fit<bestFit):\n",
    "                bestFit=fit\n",
    "                bestc = [c9,c10]\n",
    "                bestq = allQSquareCoeffs\n",
    "                print(bestc)\n",
    "                print(bestq)\n",
    "                print(fit)\n",
    "            X.append(x)\n",
    "            #X.append(x + [fit])\n",
    "            \n",
    "            \n",
    "            Y.append(y.tolist()) \n",
    "            \n",
    "        \n",
    "    \n",
    "    generateExperimental()\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)  \n",
    "    \n",
    "    \n",
    "    saveData(\"X_NN_With_Coeffs.pickle\", X)\n",
    "    saveData(\"y_NN_With_Coeffs.pickle\", Y)\n",
    "    \n",
    "    saveData(\"coeffs_noChi.pickle\", coeffs)  \n",
    "    print(bestFit)\n",
    "    print(bestc)\n",
    "    print(bestq)\n",
    "    \n",
    "\n",
    "    \n",
    "def loadObservables():\n",
    "    DATADIR = 'data/models/observables' \n",
    "    EXPDIR = 'data/experimental'  \n",
    "    observables = []\n",
    "    \n",
    "    P1 = getObservablesByName(DATADIR, EXPDIR, ['P1'])\n",
    "    P2 = getObservablesByName(DATADIR, EXPDIR, ['P2'])\n",
    "    P4 = getObservablesByName(DATADIR, EXPDIR, ['P4'])\n",
    "    P5 = getObservablesByName(DATADIR, EXPDIR, ['P5'])\n",
    "    BRK0Starmumu = getObservablesByName(DATADIR, EXPDIR, ['BRK0Starmumu'])\n",
    "    BRK0mumu = getObservablesByName(DATADIR, EXPDIR, ['BRK0mumu'])\n",
    "    RK = getObservablesByName(DATADIR, EXPDIR, ['RK'])\n",
    "    RKStar = getObservablesByName(DATADIR, EXPDIR, ['RKStar'])    \n",
    "    #\n",
    "    observables = np.array([P1, P2, P4, P5, BRK0Starmumu, BRK0mumu, RK, RKStar])\n",
    "    observables = observables.reshape((8,2))\n",
    "    \n",
    "    #observables = np.array([RKStar])\n",
    "    #observables = observables.reshape((1,2))\n",
    "    \n",
    "    \n",
    "    #observables = np.array([P1])\n",
    "    #observables = observables.reshape((1,2))\n",
    "    return observables\n",
    "\n",
    "    \n",
    "def getRandomModels():\n",
    "    #c9 = np.round(np.linspace(-2, 0, num=10), 2)\n",
    "    #c10 = np.round(np.linspace(-1, 1, num=10), 2)    \n",
    "    c9 = np.round(np.linspace(-5, 5, num=10), 2)\n",
    "    c10 = np.round(np.linspace(-5, 5, num=10), 2)    \n",
    "    models = np.meshgrid(c9, c10)    \n",
    "    \n",
    "    r = np.array([(x,y) for a,b in zip(models[0], models[1]) for x,y in zip(a,b)]) \n",
    "    #r = np.array([(x,y) for x,y in zip(c9,c10)])      \n",
    "    area = np.pi*2\n",
    "    # Plot\n",
    "    plt.scatter(r[:,0], r[:,1], s=area, alpha=1)\n",
    "    plt.show() \n",
    "    return r   \n",
    "\n",
    "def generateNearZeroSamples(num):\n",
    "    result =[]\n",
    "    pickle_in = open(\"X_experimental.pickle\", \"rb\")\n",
    "    X_experimental = pickle.load(pickle_in)\n",
    "\n",
    "\n",
    "    pickle_in = open(\"errors.pickle\", \"rb\")\n",
    "    errors = pickle.load(pickle_in)\n",
    "    errors= np.array(errors[:,1])\n",
    "    Y = []\n",
    "    \n",
    "    for i in range(num):    \n",
    "        newSample = np.random.normal(X_experimental, 0.1)\n",
    "        f = computeModelFit2(newSample, X_experimental,errors,errors)    \n",
    "        Y.append(int(round(f)))\n",
    "        result.append((newSample).tolist())\n",
    "    \n",
    "    saveData(\"X_NearZero_experimental.pickle\", result)\n",
    "    saveData(\"y_NearZero_experimental.pickle\", Y)\n",
    "    return result\n",
    "  \n",
    "def computeModelFit2(bins,binsExp,errorModel, errorExp):\n",
    "    \n",
    "    binFits = [computeChiSquare(muModel, muExp, errorModel, errorExp) for muModel, muExp, errorModel, errorExp in zip(bins,binsExp,errorModel,errorExp)]      \n",
    "    s = sum(binFits)\n",
    "    return s\n",
    "    \n",
    "def rnd():\n",
    "    exp = random.randint(-19, -15)\n",
    "    base = 10 * random.random() - 1\n",
    "    #return base * 10**exp\n",
    "    #return random.random()\n",
    "    return round(random.uniform(-1, 1),2)\n",
    "    return round(random.uniform(-0.010, 0.010),2)\n",
    "    \n",
    "\n",
    "\n",
    "def computeModelCoeffsFit(coeffs, q2coeffs):\n",
    "    observables = loadObservables() \n",
    "    c9, c10 = coeffs[0]\n",
    "    fits=[]\n",
    "    numObs = 0\n",
    "    for mo, eo in observables:\n",
    "        dfm = mo['data']\n",
    "        dfe = eo['data'] \n",
    "        computeModelObservable(dfm,c9, c10)\n",
    "\n",
    "        if(len(q2coeffs) > 0):\n",
    "            \n",
    "            addQPoly(dfm, q2coeffs[numObs])\n",
    "\n",
    "        fit = computeModelFit(dfm, dfe)\n",
    "        \n",
    "        fits.append(fit)\n",
    "        numObs = numObs+1\n",
    "        \n",
    "    return np.array(fits).sum()\n",
    "        \n",
    "        \n",
    "\n",
    "   \n",
    "#computeAllModelsAllFit()\n",
    "#computeRandomModelsFit(getObservablesByName('data/models/observables' ,'data/experimental', observableNames))\n",
    "#print(computeModelsLFUVFit())\n",
    "#observableNames = ['P1', 'P2', 'P4', 'P5', 'BRK0Starmumu', 'BRK0mumu', 'RK', 'RKStar']\n",
    "#r = computeModelsFit([[-0.2,  0.002]], getObservablesByName('data/models/observables' ,'data/experimental', observableNames))\n",
    "#print(r)\n",
    "#getObservablesByName('data/models/observables','data/experimental/' ,['P1', 'P2'])\n",
    "#getRandomModels()\n",
    "#generateNNData()\n",
    "#generateGANData()\n",
    "#generateExperiment1GANData()\n",
    "\n",
    "#generateExperimental()\n",
    "\n",
    "# Pass 2d array of coeffs ex: [[-0.5, 0.5], [-1, 0]]\n",
    "#plotAllModelsObservables(getCoeffsFromModels(getModels()))\n",
    "#generateTrueImages()\n",
    "#generateTestData()\n",
    "#getRandomModels()\n",
    "\n",
    "#generateNearZeroSamples(500)\n",
    "#generateGANData()\n",
    "\n",
    "\n",
    "#generateGANData3()\n",
    "#generateBinErrors()\n",
    "#generateObservableNumBins()\n",
    "\n",
    "#generateNearZeroSamples(1)\n",
    "#genNNData()\n",
    "#genNNWithCoeffsData()\n",
    "#plotAllModelsObservables([[-0.5,0.5 ]],[])\n",
    "\n",
    "#a = [-1.5  , 0 ,  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "#a=[-3.54 , 2.16 , 3.7336019e-06 , 1.6394207e-11,\n",
    "#   1.4970936e-10]\n",
    "#a=[-1.7165524e+01, -6.6029954e-01,  1.5080704e-07 , 6.0016580e-14,\n",
    "#   7.8496305e-07]\n",
    "#a=[-8.8368118e-02 , 3.6405189e+00  ,1.3597724e-04, -2.5137824e-06,\n",
    "#   3.4012530e-08]\n",
    "#a = [-0.89, 0.11,0. ,   0. ,   0. ,  -0.01 , 0. ,   0.  , -0. ,   0.  ,  0.,   -0.01 , 0.,   -0.,\n",
    "# -0.01, -0. ,   0. , -0.   ,-0. ,  -0. ,   0.01,  0.  ,  0. ,  -0. ,   0.  , -0. ]\n",
    "#\n",
    "#c_coeffs = a[0:2]\n",
    "#q_coeffs = np.reshape(a[2:],(8,3))\n",
    "#plotAllModelsObservables([c_coeffs], q_coeffs)\n",
    "#q_coeffs =[  -0.03988467 ,-0.00952338, -0.02897049, -0.01798573,\n",
    "#   0.02654165, -0.00204922,  0.01819788,  0.02741509 ,-0.0141378,   0.01511815,\n",
    "#  -0.01185841, -0.0074015 ,  0.01569612, -0.00738949,  0.00957566 , 0.0051719,\n",
    "#  -0.00373101, -0.00093994,  0.00204237,  0.01116721 , 0.01137767, -0.00681933,\n",
    "#  -0.03441897,  0.01032308]\n",
    "##\n",
    "#q_coeffs = np.reshape(q_coeffs,(8,3))\n",
    "#\n",
    "#print(q_coeffs)\n",
    "#computeModelCoeffsFit([[-0.4532434,  -0.2337412]],q_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.00386232979719"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.uniform(-10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.random([-5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.colors as Colors\n",
    "from matplotlib.patches import Polygon\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rcParams['text.latex.preamble']=[r\"\\usepackage{amsmath}\"]    \n",
    "def plotObservable2(ax, binValues, bins, binWidths, binValuesErrors, color,kcolor):   \n",
    "    # Set height minimum\n",
    "    binValuesErrors = [0.01 if a_ < 0.01 else a_ for a_ in binValuesErrors]\n",
    "    patches = [Rectangle((x,y), w, h) for x,y,w,h in zip(bins,binValues, binWidths, binValuesErrors)]\n",
    "       \n",
    "    p = PatchCollection(patches, facecolor=Colors.to_rgba(color, 1))    \n",
    "    ax.add_collection(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"histLogChisquare.pickle\", \"rb\")\n",
    "histLogChisquare = pickle.load(pickle_in)\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rcParams['text.latex.preamble']=[r\"\\usepackage{amsmath}\"]  \n",
    "bin_edges = np.linspace(start= histLogChisquare.min(), stop=histLogChisquare.max()+1, num=np.unique(histLogChisquare).size+1, endpoint=True)\n",
    "\n",
    "plt.hist(histLogChisquare, bin_edges) \n",
    "plt.xlabel(r'\\(\\chi^2 \\)', fontsize=16)\n",
    "plt.savefig('histChisquare.svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "pickle_in = open(\"X_noChi.pickle\", \"rb\")\n",
    "X_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_noChi.pickle\", \"rb\")\n",
    "y_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"coeffs_noChi.pickle\", \"rb\")\n",
    "coeffs = pickle.load(pickle_in)\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "print(len(Counter(y_train).keys()))\n",
    "print(max(y_train))\n",
    "print(min(y_train))\n",
    "#print(X_train[1000:2000,-2:])\n",
    "#print(X_train[np.where(y_train==min(y_train))])\n",
    "#print(coeffs[np.where(y_train==min(y_train))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveData(filename, data):\n",
    "    pickle_out = open(filename, \"wb\")\n",
    "    pickle.dump(data, pickle_out)\n",
    "    pickle_out.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 37)\n"
     ]
    },
    {
     "ename": "AlreadyExistsError",
     "evalue": "Another profiler is running.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAlreadyExistsError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-95ebcf925cee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mearly_stop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mNAME\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"NN-{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0mtensorBoard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'logs/{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNAME\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, log_dir, histogram_freq, write_graph, write_images, update_freq, profile_batch, embeddings_freq, embeddings_metadata, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m         profile_batch)\n\u001b[0;32m   1736\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_batch\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1737\u001b[1;33m       \u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarmup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Improve the profiling accuracy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1738\u001b[0m     \u001b[1;31m# True when a trace is running.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1739\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_tracing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\profiler\\profiler_v2.py\u001b[0m in \u001b[0;36mwarmup\u001b[1;34m()\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m   \"\"\"\n\u001b[1;32m--> 124\u001b[1;33m   \u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m   \u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\profiler\\profiler_v2.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(logdir)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_profiler\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m       raise errors.AlreadyExistsError(None, None,\n\u001b[1;32m---> 74\u001b[1;33m                                       'Another profiler is running.')\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[0m_profiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pywrap_profiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProfilerSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAlreadyExistsError\u001b[0m: Another profiler is running."
     ]
    }
   ],
   "source": [
    "#Dependencies\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#-------------------------------------------------------------\n",
    "#NN 1 data\n",
    "#pickle_in = open(\"X_NN.pickle\", \"rb\")\n",
    "#X_train = pickle.load(pickle_in)\n",
    "#\n",
    "#pickle_in = open(\"y_NN.pickle\", \"rb\")\n",
    "#y_train = pickle.load(pickle_in)\n",
    "\n",
    "\n",
    "#NN 2 data\n",
    "pickle_in = open(\"X_NN_With_Coeffs.pickle\", \"rb\")\n",
    "X_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_NN_With_Coeffs.pickle\", \"rb\")\n",
    "y_train = pickle.load(pickle_in)\n",
    "print(X_train.shape)\n",
    "#\n",
    "pickle_in = open(\"X_experimental.pickle\", \"rb\")\n",
    "X_experimental = pickle.load(pickle_in)\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "# fit scaler on data\n",
    "scaler.fit(X_train)\n",
    "# apply transform\n",
    "X_train = scaler.transform(X_train)\n",
    "#-------------------------------------------------------------\n",
    "early_stop = EarlyStopping(monitor='val_mean_squared_error', mode='min', patience=10)\n",
    "NAME = \"NN-{}\".format(int(time.time()))\n",
    "tensorBoard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "\n",
    "\n",
    "pp=[]\n",
    "#model.summary()\n",
    "highest_fit = 100000000\n",
    "highest_coefs = []\n",
    "scaler.fit([X_experimental])\n",
    "X_experimental = scaler.transform([X_experimental])\n",
    "for i in range(25):\n",
    "    print(i)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(3, input_dim=37, activation='relu'))      \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #model.add(Dense(780, activation='relu'))\n",
    "    #-------------------------------------------------------------\n",
    "    # Output for NN1\n",
    "    #model.add(Dense(2))\n",
    "    # Output for NN2\n",
    "    model.add(Dense(26))\n",
    "    #--------------------------------------------------------------\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    history = model.fit(X_train, y_train, batch_size=512, epochs=100, validation_split=0.1, callbacks=[tensorBoard,early_stop], verbose=0, shuffle=True)\n",
    "    \n",
    "    #p = model.predict(np.reshape(np.append(X_experimental[0:6],[0]),(1,7)))\n",
    "    #p = model.predict(np.reshape(np.append(X_experimental,[0]),(1,38)))\n",
    "    p = model.predict(np.reshape(X_experimental,(1,37)))\n",
    "    q_coeffs = np.reshape(p[0][2:],(8,3) )\n",
    "    fit = computeModelCoeffsFit([p[0][0:2]],q_coeffs)\n",
    "    \n",
    "    if(fit<highest_fit):\n",
    "        highest_fit = fit\n",
    "        highest_coefs = p\n",
    "        print(fit)\n",
    "    \n",
    "    \n",
    "#\n",
    "    pp.append(p);\n",
    "print(highest_fit)\n",
    "print(highest_coefs)\n",
    "\n",
    "    \n",
    "pp = np.array(pp)\n",
    "saveData('pp.pickle', pp)\n",
    "\n",
    "#scaler.fit([X_experimental])\n",
    "## apply transform\n",
    "#X_experimental = scaler.transform([X_experimental])\n",
    "#p = model.predict(np.reshape(np.append(X_experimental[0:6],[0]),(1,7)))\n",
    "#\n",
    "#print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31.321334976651187"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "computeModelCoeffsFit([[-1,0]], [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X_experimental.pickle\", \"rb\")\n",
    "X_experimental = pickle.load(pickle_in)\n",
    "print(np.array(X_experimental).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pickle_in = open(\"X_NN.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rc('text', usetex=True)\n",
    "pickle_in = open(\"pp.pickle\", \"rb\")\n",
    "pp = pickle.load(pickle_in)\n",
    "print(pp)\n",
    "pp = np.reshape(pp, (100,2))\n",
    "xedges = [-2,-1, 0, 1, 2]\n",
    "yedges = [-2,-1, 0, 1, 2]\n",
    "H, xedges, yedges = np.histogram2d(pp[:,0], pp[:,1], bins=(xedges, yedges))\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "\n",
    "ax = fig.add_subplot()\n",
    "ax.set_xlabel(r'\\(C_{9}\\)',fontsize=48, labelpad=30)\n",
    "ax.set_ylabel(r'\\(C_{10}\\)',fontsize=48, labelpad=10)\n",
    "ax.set_xticks(np.arange(-2, 2,0.5))\n",
    "ax.set_yticks(np.arange(-2, 2,0.5))\n",
    "\n",
    "plt.imshow(H, interpolation='nearest', origin='low',\n",
    "        extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]])\n",
    "\n",
    "plt.colorbar()\n",
    "plt.savefig('predictedCoeffs.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=True)\n",
    "plt.rcParams['text.latex.preamble']=[r\"\\usepackage{amsmath}\"]    \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_ylabel(r'\\(\\boldsymbol{C_{10}}\\)', fontsize=16)\n",
    "ax.set_xlabel(r'\\(\\boldsymbol{C_{9}}\\)', fontsize=16)\n",
    "h = ax.hist2d(x, y, bins=10)\n",
    "fig.colorbar(h[3], ax=ax)\n",
    "plt.show()\n",
    "fig.savefig('NN_predictions.svg')\n",
    "print(type(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiOutput Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple NN one sigmoid, binary_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Neural Netwok 2 sigmoids, categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple NN one softmax, categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

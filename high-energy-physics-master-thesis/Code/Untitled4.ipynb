{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Pandas libraries with alias 'pd' \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.colors as Colors\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.stats import entropy\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import math\n",
    "from scipy.stats import chisquare\n",
    "from scipy import stats\n",
    "from itertools import product\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "def plotAllModelsObservables(models, coeffs):\n",
    "    \n",
    "    \n",
    "    observables = loadObservables()\n",
    "    \n",
    "    numObservables = len(observables)\n",
    "    nrows = math.ceil(numObservables/2)\n",
    "    ncols = 2\n",
    "    nrows =3\n",
    "    ncols =3\n",
    "    imageWidth = 6\n",
    "    imageHeight = 5\n",
    "    hspace = 0.5\n",
    "    wspace = 0.5\n",
    "    figureHeight = nrows * imageHeight + (nrows - 1) * hspace\n",
    "    figureWidth = ncols * imageWidth + (ncols - 1) * wspace\n",
    "    \n",
    "    plt.rc('text', usetex=True)\n",
    "    plt.rcParams['text.latex.preamble']=[r\"\\usepackage{amsmath}\"]    \n",
    "    \n",
    "    \n",
    "    for C9, C10 in models:    \n",
    "        index = 1\n",
    "        fig, axs = plt.subplots(nrows,ncols)\n",
    "        fig.subplots_adjust(left=None, right=None, bottom=None, top=0.90, hspace=hspace, wspace=wspace)  \n",
    "        fig.set_figheight(figureHeight)\n",
    "        fig.set_figwidth(figureWidth)\n",
    "        fig.delaxes(axs[2,2])\n",
    "        axs = np.reshape(axs,(-1))\n",
    "        axis_index = 0\n",
    "        allFits=[]\n",
    "        for mo, eo in observables:\n",
    "            \n",
    "            #fig.suptitle(title, fontsize=18) \n",
    "            df = mo['data']\n",
    "            de = eo['data']\n",
    "            \n",
    "            ax = axs[axis_index]            \n",
    "            \n",
    "            observableName = mo['name']\n",
    "            \n",
    "            ax.set_xlabel(r'\\(\\boldsymbol{q^2(GeV^2)}\\)', fontsize=16)\n",
    "            print(observableName)\n",
    "            if(observableName == 'RKStar'):\n",
    "                ytitle = 'R'\n",
    "                ax.set_ylabel(r'\\(\\langle \\boldsymbol{{{}_K^*}} \\rangle\\)'.format(ytitle), fontsize=16)\n",
    "            elif(observableName=='BRK0mumu'):\n",
    "                ytitle = 'B'\n",
    "                ax.set_ylabel(r'\\(\\langle \\boldsymbol{{\\mathcal{B}(B^0\\rightarrow K\\mu\\mu)}} \\rangle\\)', fontsize=16)\n",
    "            elif(observableName=='BRK0Starmumu'):\n",
    "                ytitle = 'B'\n",
    "                ax.set_ylabel(r'\\(\\langle \\boldsymbol{{\\mathcal{B}(B^0\\rightarrow K^{*0}\\mu\\mu)}} \\rangle\\)', fontsize=16)\n",
    "            elif(observableName == 'P5'):\n",
    "                ytitle = 'P'\n",
    "                ax.set_ylabel(r'\\(\\langle \\boldsymbol{{{}_5}} \\rangle\\)'.format(ytitle), fontsize=16)\n",
    "            else:\n",
    "                ax.set_ylabel(r'\\(\\langle \\boldsymbol{{{}}} \\rangle\\)'.format(observableName), fontsize=16)\n",
    "                \n",
    "            computeModelObservable(df, C9, C10)\n",
    "            if(len(coeffs) > 0):\n",
    "                addQPoly(df,coeffs[axis_index])\n",
    "                \n",
    "            fit = computeModelFit(df, de)\n",
    "            print(fit)\n",
    "            print(coeffs[axis_index])\n",
    "            allFits.append(fit)\n",
    "            ax.set_title(r'\\(\\chi^2:{} \\)'.format(round(fit,2)), fontsize=20)\n",
    "            ax.set_xlim(0, max(df['BinHigh'].max(), de['BinHigh'].max()))\n",
    "            ax.set_ylim([min(df['MinValue'].min(),de['MinValue'].min()), max(df['MaxValue'].max(),de['MaxValue'].max())])\n",
    "            \n",
    "            plotObservable(ax, df, 'orange', 'black', 1)\n",
    "            plotObservable(ax, de, 'black', 'green', 0, True, True)\n",
    "            index = index + 1 \n",
    "            \n",
    "            axis_index = axis_index + 1\n",
    "        title = r'Model: C9: {}, C10: {}, \\(\\chi^2: {} \\)'.format(round(C9,2), round(C10,2),round(np.array(allFits).sum(),2))         \n",
    "        fig.suptitle(title, fontsize=24) \n",
    "        fig.savefig('observableImages/{}.svg'.format('AllObservables'))\n",
    "    plt.show()\n",
    "   \n",
    "    \n",
    "    \n",
    "def expandObservableData(df):\n",
    "    df['Widths'] = df['BinHigh'] - df['BinLow']\n",
    "    df['Heights'] = df['ErrorPlus'] + df['ErrorMinus']  \n",
    "    \n",
    "       \n",
    "\n",
    "def plotObservable(ax, df, color,kcolor, opacity, yerrorbar = False, onlyErrorBars = False):   \n",
    "    patches = [Rectangle((x,y), w, h) for x,y,w,h in zip(df['BinLow'], df['MinValue'], df['Widths'], df['Heights'])]\n",
    "    xerror = [df['Widths'] / 2, df['Widths'] / 2]    \n",
    "    \n",
    "    if(not onlyErrorBars):\n",
    "        p = PatchCollection(patches, facecolor=Colors.to_rgba(color, opacity))\n",
    "        ax.add_collection(p)       \n",
    "    ax.errorbar(df['BinLow'] + df['Widths']/2, df['BinValue'], xerr=xerror, fmt='None', ecolor=Colors.to_rgba(kcolor, 1))\n",
    "    if(yerrorbar):\n",
    "        yerror = [df['Heights'] / 2, df['Heights'] / 2] \n",
    "        ax.errorbar(df['BinLow'] + df['Widths']/2, df['BinValue'], yerr=yerror, fmt='None', ecolor=Colors.to_rgba(kcolor, 1))\n",
    "\n",
    "\n",
    "def computePoly(binCoeffs,c9,c10):\n",
    "    a = binCoeffs[0]\n",
    "    b = binCoeffs[1]*c10\n",
    "    c = binCoeffs[2]*c10**2\n",
    "    d = binCoeffs[3]*c9\n",
    "    e = binCoeffs[4]*c10*c9\n",
    "    f = binCoeffs[5]*c9**2\n",
    "    return a + b + c  + d + e + f\n",
    "\n",
    "def getBinValuesFreeCoeffs(df, c9, c10, observableCoeffs):     \n",
    "    df['BinValue'] = [computePoly(binCoeffs,c9,c10) for binCoeffs in observableCoeffs]\n",
    "    \n",
    "        \n",
    "def getBinValues(df, C9, C10):     \n",
    "    df2 = df.copy();       \n",
    "    df2['C10'] = df2['C10']*C10\n",
    "    df2['C10^2'] = df2['C10^2']*C10**2\n",
    "    df2['C9'] = df2['C9']*C9\n",
    "    df2['C10*C9']=df2['C10*C9']*C10*C9\n",
    "    df2['C9^2'] = df2['C9^2']*C9**2    \n",
    "    df['BinValue'] = df['C0'] + df2['C10'] + df2['C10^2'] + df2['C9'] + df2['C10*C9'] + df2['C9^2']\n",
    "    df['MinValue'] = df['BinValue'] - df['ErrorMinus']\n",
    "    df['MaxValue'] = df['BinValue'] + df['ErrorPlus']\n",
    "\n",
    "def getModelObservable(DATADIR, filename) :\n",
    "    return getObservable(DATADIR, filename)\n",
    "\n",
    "def getExpObservable(DATADIR, filename) :\n",
    "    eo = getObservable(DATADIR, filename)\n",
    "    df = eo['data']\n",
    "    df['MinValue'] = df['BinValue'] - df['ErrorMinus']\n",
    "    df['MaxValue'] = df['BinValue'] + df['ErrorPlus']\n",
    "    return eo\n",
    "\n",
    "def getObservable(DATADIR, filename):\n",
    "    try:  \n",
    "        df = pd.read_csv(os.path.join(DATADIR, filename))\n",
    "        expandObservableData(df)\n",
    "        fname = filename.split('.')[0]              \n",
    "        return {'name': fname, 'data': df}\n",
    "    except Exception as e:\n",
    "        print('Exception',e)\n",
    "        pass\n",
    "    \n",
    "def computeModelFit2(dfm, dfe):\n",
    "    data = zip(dfm['BinValue'], dfe['BinValue'], (dfm['ErrorPlus']+dfm['ErrorMinus'])/2, (dfe['ErrorPlus']+dfe['ErrorMinus'])/2)\n",
    "    binFits = [computeChiSquare(muModel, muExp, sigmaModel, sigmaExp) for muModel, muExp, sigmaModel, sigmaExp in data]      \n",
    "    s = sum(binFits)\n",
    "    return s\n",
    "        \n",
    "def computeChiSquare(muModel, muExp, sigmaModel, sigmaExp):   \n",
    "    return (muExp - muModel)**2/(sigmaModel**2 + sigmaExp**2)\n",
    "    \n",
    "\n",
    "def getObservables(DATADIR, EXPDIR, names):\n",
    "    observables = []\n",
    "    for filename in names:\n",
    "        mo = getModelObservable(DATADIR, filename)        \n",
    "        eo = getExpObservable(EXPDIR, filename)\n",
    "        observables.append([mo, eo])\n",
    "    return observables\n",
    "    \n",
    "def getAllObservables():\n",
    "    DATADIR = 'data/models/observables' \n",
    "    EXPDIR = 'data/experimental'     \n",
    "    onlyfiles = [f for f in listdir(DATADIR) if isfile(join(DATADIR, f))]    \n",
    "    return getObservables(DATADIR, EXPDIR, onlyfiles)   \n",
    "\n",
    "def computeRandomModelsFit(observables):    \n",
    "    models = getRandomModels()\n",
    "    return computeModelsFit(models, observables)    \n",
    "\n",
    "def getCoeffsFromModels(models):\n",
    "    m = [[c9, c10] for c9, c10 in zip(models['C9'], models['C10'])]\n",
    "    return m\n",
    "    \n",
    "def getModels():\n",
    "    MODELSDIR = 'data/models'  \n",
    "    mfilename = 'models1.txt'    \n",
    "    models = pd.read_csv(os.path.join(MODELSDIR, mfilename))\n",
    "    return models\n",
    "\n",
    "def addQPoly(dfe, coeffs):\n",
    "    dfe['q^2'] = (dfe['BinHigh'] + dfe['BinLow']) / 2\n",
    "    \n",
    "    dfe['Fq^2Net'] = coeffs[0]  + coeffs[1] * dfe['q^2'] + coeffs[2] * dfe['q^2']**2\n",
    "    \n",
    "    dfe['BinValueOld'] = dfe['BinValue']\n",
    "    dfe['BinValue'] = dfe['BinValue'] + dfe['Fq^2Net']  \n",
    "    dfe['BinValueDiff'] = dfe['BinValue'] - dfe['BinValueOld']\n",
    "    dfe['MinValue'] = dfe['BinValue'] - dfe['ErrorMinus']\n",
    "    dfe['MaxValue'] = dfe['BinValue'] + dfe['ErrorPlus']\n",
    "    \n",
    "        \n",
    "def computeModelObservable(df, C9, C10):\n",
    "    getBinValues(df,C9, C10) \n",
    "    expandObservableData(df)\n",
    "\n",
    "def getObservablesByName(DATADIR, EXPDIR, names):\n",
    "    names = [f for f in listdir(DATADIR) if isfile(join(DATADIR, f)) and f.split('.')[0] in names]\n",
    "    return getObservables(DATADIR, EXPDIR, names)     \n",
    "\n",
    "    \n",
    "def computeAllModelsAllFit():\n",
    "    DATADIR = 'data/models/observables' \n",
    "    EXPDIR = 'data/experimental'  \n",
    "    models = getModels()\n",
    "    m = getCoeffsFromModels(models)\n",
    "    observables = getAllObservables()\n",
    "    #observables = getObservablesByName(DATADIR, EXPDIR, ['P5'])\n",
    "    return computeModelsFit(m, observables)\n",
    "\n",
    "def getValue(value, low, high ):    \n",
    "    #print('value: {}, high: {}, low: {}, newValue: {}'.format(value,high,low, random.uniform(value - low, value + high)))\n",
    "    return np.random.normal(value, low)\n",
    "\n",
    "def generateExperimental():    \n",
    "    observables = loadObservables()\n",
    "    x = np.array([])\n",
    "    for mo, eo in observables:\n",
    "        dfe = eo['data']\n",
    "        x = np.append(x, dfe['BinValue'].values)\n",
    "        \n",
    "    saveData(\"X_experimental.pickle\", x)\n",
    "    return x\n",
    "\n",
    "def saveData(filename, data):\n",
    "    pickle_out = open(filename, \"wb\")\n",
    "    pickle.dump(data, pickle_out)\n",
    "    pickle_out.close()         \n",
    "\n",
    "    \n",
    "def generateBinErrors():\n",
    "    observables = loadObservables() \n",
    "    \n",
    "    errors = np.empty([0,6]);\n",
    "    for mo, eo in observables:\n",
    "        \n",
    "        dfm = mo['data']\n",
    "        dfe = eo['data']\n",
    "        expandObservableData(dfm)\n",
    "        expandObservableData(dfe)\n",
    "        dfmErrorMinus = dfm['ErrorMinus']  \n",
    "        dfeErrorMinus = dfe['ErrorMinus']  \n",
    "        dfmError = dfm['Heights'].values / 2\n",
    "        dfeError = dfe['Heights'].values / 2\n",
    "        widths = dfe['Widths'].values\n",
    "        bins = dfm['BinLow'].values\n",
    "        errors = np.append(errors, [[a,b,c,d,e,f] for a,b,c,d,e,f in zip(dfmError,dfeError,widths,bins,dfmErrorMinus,dfeErrorMinus)],axis=0)\n",
    "     \n",
    "    saveData(\"errors.pickle\", errors)\n",
    "    \n",
    "\n",
    "def generateObservableNumBins():\n",
    "    observables = loadObservables() \n",
    "    \n",
    "    numBins = []\n",
    "    for mo, eo in observables:\n",
    "        dfe = eo['data']\n",
    "        numBins.append(len(dfe.index))\n",
    "     \n",
    "    saveData(\"numBins.pickle\", numBins)\n",
    "    print(numBins)\n",
    "\n",
    "\n",
    "    \n",
    "def genNNData():\n",
    "    observables = loadObservables()  \n",
    "    models = getRandomModels()\n",
    "   \n",
    "    X = []\n",
    "    Y = []\n",
    "    coeffs = []\n",
    "    iter=0   \n",
    "    bestFit=100000\n",
    "    bestc=[]\n",
    "    allFits=[]\n",
    "    for c9, c10 in models:\n",
    "        print(iter)\n",
    "        iter=iter+1             \n",
    "            \n",
    "       \n",
    "        x = []\n",
    "        y = np.array([])\n",
    "\n",
    "        fits=[]        \n",
    "\n",
    "        for mo, eo in observables:\n",
    "            dfm = mo['data']\n",
    "            dfe = eo['data']                \n",
    "\n",
    "            computeModelObservable(dfm,c9, c10)\n",
    "\n",
    "\n",
    "            fit = computeModelFit(dfm, dfe)\n",
    "            fits.append(fit)                \n",
    "\n",
    "            x = x + dfm['BinValue'].values.tolist()          \n",
    "\n",
    "\n",
    "        y = np.append(y,[c9,c10])     \n",
    "       \n",
    "        fit = np.array(fits).sum()\n",
    "        allFits.append(fit)\n",
    "     \n",
    "        if(fit<bestFit):\n",
    "            bestFit=fit\n",
    "            bestc = [c9,c10]\n",
    "            print(bestc)\n",
    "            print(fit)\n",
    "            \n",
    "        # FOR GAN -----------------------------\n",
    "        x = x + [c9,c10]\n",
    "        #--------------------------------------\n",
    "        X.append(x)\n",
    "        \n",
    "        Y.append(y.tolist()) \n",
    "            \n",
    "        \n",
    "    \n",
    "    generateExperimental()\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)  \n",
    "    \n",
    "    \n",
    "    saveData(\"X_NN.pickle\", X)\n",
    "    saveData(\"y_NN.pickle\", Y)\n",
    "    saveData(\"histLogChisquare.pickle\", allFits)\n",
    "    \n",
    "    print(bestFit)\n",
    "    print(bestc)\n",
    "    print(X[0])\n",
    "    \n",
    "    \n",
    "def genNNWithCoeffsData():\n",
    "    observables = loadObservables()  \n",
    "    models = getRandomModels()\n",
    "   \n",
    "    X = []\n",
    "    Y = []\n",
    "    coeffs = []\n",
    "    numPolyCoeffs = 100\n",
    "    iter=0   \n",
    "    bestFit=100000\n",
    "    bestq=[]\n",
    "    bestc=[]\n",
    "    for c9, c10 in models:\n",
    "        print(iter)\n",
    "        iter=iter+1        \n",
    "        \n",
    "        for i in range(numPolyCoeffs):  \n",
    "            \n",
    "            allFits = []      \n",
    "            x = []\n",
    "            y = np.array([])\n",
    "            allQSquareCoeffs = np.array([])            \n",
    "            fits=[]\n",
    "            numObs = 0\n",
    "            \n",
    "            for mo, eo in observables:\n",
    "                dfm = mo['data']\n",
    "                dfe = eo['data']                \n",
    "                \n",
    "                computeModelObservable(dfm,c9, c10)\n",
    "                \n",
    "                if(i==0):\n",
    "                    QSsquareCoeffs = np.random.uniform(0, 0, 3)                \n",
    "                else:\n",
    "                    QSsquareCoeffs = [rnd() for _ in range(3)]\n",
    "                    QSsquareCoeffs[1] = QSsquareCoeffs[1]/10\n",
    "                    QSsquareCoeffs[2] = QSsquareCoeffs[2]/100\n",
    "                    QSsquareCoeffs = np.round(QSsquareCoeffs,2)\n",
    "                  \n",
    "                \n",
    "                allQSquareCoeffs = np.append(allQSquareCoeffs, QSsquareCoeffs)                \n",
    "                addQPoly(dfm, QSsquareCoeffs)                \n",
    "                fit = computeModelFit(dfm, dfe)\n",
    "                fits.append(fit)                \n",
    "                \n",
    "                x = x + dfm['BinValue'].values.tolist()\n",
    "                numObs = numObs + 1\n",
    "                \n",
    "            \n",
    "            y = np.append(y,[c9,c10])     \n",
    "            y = np.append(y, allQSquareCoeffs)\n",
    "            fit = np.array(fits).sum()\n",
    "            if(fit<bestFit):\n",
    "                bestFit=fit\n",
    "                bestc = [c9,c10]\n",
    "                bestq = allQSquareCoeffs\n",
    "                print(bestc)\n",
    "                print(bestq)\n",
    "                print(fit)\n",
    "            X.append(x)\n",
    "            #X.append(x + [fit])\n",
    "            \n",
    "            \n",
    "            Y.append(y.tolist()) \n",
    "            \n",
    "        \n",
    "    \n",
    "    generateExperimental()\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)  \n",
    "    \n",
    "    \n",
    "    saveData(\"X_NN_With_Coeffs.pickle\", X)\n",
    "    saveData(\"y_NN_With_Coeffs.pickle\", Y)\n",
    "    \n",
    "    saveData(\"coeffs_noChi.pickle\", coeffs)  \n",
    "    print(bestFit)\n",
    "    print(bestc)\n",
    "    print(bestq)\n",
    "    \n",
    "\n",
    "    \n",
    "def loadObservables():\n",
    "    DATADIR = 'data/models/observables' \n",
    "    EXPDIR = 'data/experimental'  \n",
    "    observables = []\n",
    "    \n",
    "    P1 = getObservablesByName(DATADIR, EXPDIR, ['P1'])\n",
    "    P2 = getObservablesByName(DATADIR, EXPDIR, ['P2'])\n",
    "    P4 = getObservablesByName(DATADIR, EXPDIR, ['P4'])\n",
    "    P5 = getObservablesByName(DATADIR, EXPDIR, ['P5'])\n",
    "    BRK0Starmumu = getObservablesByName(DATADIR, EXPDIR, ['BRK0Starmumu'])\n",
    "    BRK0mumu = getObservablesByName(DATADIR, EXPDIR, ['BRK0mumu'])\n",
    "    RK = getObservablesByName(DATADIR, EXPDIR, ['RK'])\n",
    "    RKStar = getObservablesByName(DATADIR, EXPDIR, ['RKStar'])    \n",
    "    #\n",
    "    observables = np.array([P1, P2, P4, P5, BRK0Starmumu, BRK0mumu, RK, RKStar])\n",
    "    observables = observables.reshape((8,2))\n",
    "    \n",
    "    #observables = np.array([RKStar])\n",
    "    #observables = observables.reshape((1,2))\n",
    "    \n",
    "    \n",
    "    #observables = np.array([P1])\n",
    "    #observables = observables.reshape((1,2))\n",
    "    return observables\n",
    "\n",
    "    \n",
    "def getRandomModels():\n",
    "    #c9 = np.round(np.linspace(-2, 0, num=10), 2)\n",
    "    #c10 = np.round(np.linspace(-1, 1, num=10), 2)    \n",
    "    c9 = np.round(np.linspace(-5, 5, num=50), 2)\n",
    "    c10 = np.round(np.linspace(-5, 5, num=50), 2)    \n",
    "    models = np.meshgrid(c9, c10)    \n",
    "    \n",
    "    r = np.array([(x,y) for a,b in zip(models[0], models[1]) for x,y in zip(a,b)]) \n",
    "    #r = np.array([(x,y) for x,y in zip(c9,c10)])      \n",
    "    area = np.pi*2\n",
    "    # Plot\n",
    "    plt.scatter(r[:,0], r[:,1], s=area, alpha=1)\n",
    "    plt.show() \n",
    "    return r   \n",
    "\n",
    "\n",
    "    \n",
    "def rnd():\n",
    "    exp = random.randint(-19, -15)\n",
    "    base = 10 * random.random() - 1\n",
    "    #return base * 10**exp\n",
    "    #return random.random()\n",
    "    return round(random.uniform(-1, 1),2)\n",
    "    return round(random.uniform(-0.010, 0.010),2)\n",
    "    \n",
    "\n",
    "\n",
    "def computeModelCoeffsFit(coeffs, q2coeffs):\n",
    "    observables = loadObservables() \n",
    "    c9, c10 = coeffs[0]\n",
    "    fits=[]\n",
    "    numObs = 0\n",
    "    for mo, eo in observables:\n",
    "        dfm = mo['data']\n",
    "        dfe = eo['data'] \n",
    "        computeModelObservable(dfm,c9, c10)\n",
    "\n",
    "        if(len(q2coeffs) > 0):            \n",
    "            addQPoly(dfm, q2coeffs[numObs])\n",
    "\n",
    "        fit = computeModelFit2(dfm, dfe)\n",
    "        \n",
    "        fits.append(fit)\n",
    "        numObs = numObs+1\n",
    "        \n",
    "    return np.array(fits).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "d_hist = []\n",
    "g_hist = []\n",
    "d_accu = []\n",
    "class WGAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 8\n",
    "        self.img_cols = 8\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        # Following parameter and optimizer set as recommended in paper\n",
    "        self.n_critic = 5\n",
    "        self.clip_value = 0.01\n",
    "        optimizer = RMSprop(lr=0.00005)\n",
    "\n",
    "        # Build and compile the critic\n",
    "        self.critic = self.build_critic()\n",
    "        self.critic.compile(loss=self.wasserstein_loss,\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.critic.trainable = False\n",
    "\n",
    "        # The critic takes generated images as input and determines validity\n",
    "        valid = self.critic(img)\n",
    "\n",
    "        # The combined model  (stacked generator and critic)\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss=self.wasserstein_loss,\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 8 * 8, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((8, 8, 128)))\n",
    "        model.add(Conv2D(128, kernel_size=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(64, kernel_size=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=2, padding=\"same\"))\n",
    "        \n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_critic(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        #model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        #model.add(BatchNormalization(momentum=0.8))\n",
    "        #model.add(LeakyReLU(alpha=0.2))\n",
    "        #model.add(Dropout(0.25))\n",
    "        #model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        #model.add(BatchNormalization(momentum=0.8))\n",
    "        #model.add(LeakyReLU(alpha=0.2))\n",
    "        #model.add(Dropout(0.25))\n",
    "        #model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        #model.add(BatchNormalization(momentum=0.8))\n",
    "        #model.add(LeakyReLU(alpha=0.2))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        pickle_in = open(\"X_NN_With_Coeffs.pickle\", \"rb\")\n",
    "        X_train = pickle.load(pickle_in)\n",
    "        X_train = np.reshape(X_train, (-1,8,8))\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        \n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = -np.ones((batch_size, 1))\n",
    "        fake = np.ones((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for _ in range(self.n_critic):\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "\n",
    "                # Select a random batch of images\n",
    "                idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                imgs = X_train[idx]\n",
    "                \n",
    "                # Sample noise as generator input\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                # Generate a batch of new images\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                # Train the critic\n",
    "                d_loss_real = self.critic.train_on_batch(imgs, valid)\n",
    "                d_loss_fake = self.critic.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
    "\n",
    "                # Clip critic weights\n",
    "                for l in self.critic.layers:\n",
    "                    weights = l.get_weights()\n",
    "                    weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]\n",
    "                    l.set_weights(weights)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, 1 - d_loss[0], 1 - g_loss[0]))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.save_imgs(epoch, d_loss, g_loss)\n",
    "\n",
    "    def save_imgs(self, epoch, d_loss, g_loss):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        predictions = np.reshape(gen_imgs[0],(64))\n",
    "        print(predictions.shape)\n",
    "        realfit = computeModelCoeffsFit([predictions[37:39]],np.reshape(predictions[39:-1],(8,3)))\n",
    "        print(realfit)\n",
    "        print(predictions[37:])\n",
    "        # Rescale images 0 - 1\n",
    "        #gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        self.generator.save('generator')\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
    "        d_hist.append(d_loss[0])\n",
    "        d_accu.append(d_loss[1])\n",
    "        g_hist.append(g_loss[0])\n",
    "        fig, ax = plt.subplots(1,2)\n",
    "        fig.set_figheight(7)\n",
    "        fig.set_figwidth(15)\n",
    "        ax[0].set_xlabel(r'Iteration', fontsize=16)\n",
    "        ax[0].set_ylabel(r'Loss', fontsize=16)\n",
    "        ax[1].set_xlabel(r'Iteration', fontsize=16)\n",
    "        ax[1].set_ylabel(r'Accuracy', fontsize=16)\n",
    "        plt.xticks(fontsize=14)\n",
    "        p1 = ax[0].plot(g_hist)    \n",
    "        p2 = ax[0].plot(d_hist)\n",
    "        p3 = ax[1].plot(d_accu, color='darkorange')\n",
    "\n",
    "        ax[0].legend((p1[0], p2[0]), ('Generator', 'Discriminator'))\n",
    "        \n",
    "        plt.savefig('gendis/gendis3.svg')\n",
    "        plt.show()               \n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    wgan = WGAN()\n",
    "    wgan.train(epochs=4000, batch_size=32, sample_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt \n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "\n",
    "\n",
    "model = keras.models.load_model('generator')\n",
    "chi2=[]\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "latent_space =[]\n",
    "\n",
    "def saveData(filename, data):\n",
    "    pickle_out = open(filename, \"wb\")\n",
    "    pickle.dump(data, pickle_out)\n",
    "    pickle_out.close()  \n",
    "\n",
    "numSamples = 10000\n",
    "dim = 100\n",
    "noise = np.random.normal(0, 1, (numSamples, dim))\n",
    "\n",
    "gen_imgs = model.predict(noise)\n",
    "\n",
    "\n",
    "gen_imgs = np.reshape(gen_imgs,(numSamples, 64))\n",
    "\n",
    "bestCoeff=[]\n",
    "bestFit=999999\n",
    "for i in range(numSamples):\n",
    "    print(i)\n",
    "    \n",
    "    predictions = gen_imgs[i]\n",
    "    #v = computeModelFit(predictions,X_experimental,modelErrors,expErrors)\n",
    "    realfit = computeModelCoeffsFit([predictions[37:39]],np.reshape(predictions[39:-1],(8,3)))\n",
    "    #realfit = computeModelCoeffsFit([predictions[37:39]],[])\n",
    "    \n",
    "    chi2.append(np.round(realfit,1))\n",
    "    if(realfit<bestFit):\n",
    "        print(realfit)\n",
    "        print(predictions)\n",
    "        bestFit = realfit\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "label = np.sort(chi2)[0]\n",
    "\n",
    "print(label)\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def print_imgs():\n",
    "    r, c = 5, 5   \n",
    "    pickle_in = open(\"X_NN_With_Coeffs.pickle\", \"rb\")\n",
    "    X_train = pickle.load(pickle_in)\n",
    "    print(X_train[])\n",
    "   #X_train = np.reshape(X_train, (-1,8,8))\n",
    "   #idx = np.random.randint(0, 10000, r*c)\n",
    "\n",
    "   #gen_imgs = X_train[idx]\n",
    "   #print(gen_imgs[0])\n",
    "   ## Rescale images 0 - 1\n",
    "   ##gen_imgs = 0.5 * gen_imgs + 0.5        \n",
    "   #fig, axs = plt.subplots(r, c)\n",
    "   #cnt = 0\n",
    "   #for i in range(r):\n",
    "   #    for j in range(c):\n",
    "   #        axs[i,j].imshow(gen_imgs[cnt, :,:], cmap='gray')\n",
    "   #        axs[i,j].axis('off')\n",
    "   #        cnt += 1\n",
    "   #plt.savefig('images/trainingimages.svg')\n",
    "   #\n",
    "   #plt.show()               \n",
    "   #plt.close()\n",
    "    \n",
    "#print_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
